{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[                       0%%                      ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  2 of 2 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>^VIX^2</th>\n",
       "      <th>^SOX: Log_Returns</th>\n",
       "      <th>^VIX: Log_Returns</th>\n",
       "      <th>^VIX^2: Log_Returns</th>\n",
       "      <th>^SOX: Next_Weekly_RV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2775.000000</td>\n",
       "      <td>2775.000000</td>\n",
       "      <td>2775.000000</td>\n",
       "      <td>2774.000000</td>\n",
       "      <td>2774.000000</td>\n",
       "      <td>2774.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1371.535977</td>\n",
       "      <td>17.865077</td>\n",
       "      <td>368.874940</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.034441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>972.985329</td>\n",
       "      <td>7.052083</td>\n",
       "      <td>414.099759</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.078583</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>0.021463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>351.280029</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>83.539606</td>\n",
       "      <td>-0.173119</td>\n",
       "      <td>-0.299831</td>\n",
       "      <td>-0.599662</td>\n",
       "      <td>0.003846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>616.625000</td>\n",
       "      <td>13.230000</td>\n",
       "      <td>175.032888</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>-0.044269</td>\n",
       "      <td>-0.088538</td>\n",
       "      <td>0.020807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1084.849976</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>254.402494</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>-0.013373</td>\n",
       "      <td>0.029363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1853.179993</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>430.977710</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.071608</td>\n",
       "      <td>0.042910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4039.510010</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>6837.636504</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>0.768245</td>\n",
       "      <td>1.536490</td>\n",
       "      <td>0.271085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker         ^SOX         ^VIX       ^VIX^2  ^SOX: Log_Returns  \\\n",
       "count   2775.000000  2775.000000  2775.000000        2774.000000   \n",
       "mean    1371.535977    17.865077   368.874940           0.000725   \n",
       "std      972.985329     7.052083   414.099759           0.018136   \n",
       "min      351.280029     9.140000    83.539606          -0.173119   \n",
       "25%      616.625000    13.230000   175.032888          -0.008255   \n",
       "50%     1084.849976    15.950000   254.402494           0.001470   \n",
       "75%     1853.179993    20.760000   430.977710           0.010222   \n",
       "max     4039.510010    82.690002  6837.636504           0.105753   \n",
       "\n",
       "Ticker  ^VIX: Log_Returns  ^VIX^2: Log_Returns  ^SOX: Next_Weekly_RV  \n",
       "count         2774.000000          2774.000000           2769.000000  \n",
       "mean            -0.000046            -0.000093              0.034441  \n",
       "std              0.078583             0.157166              0.021463  \n",
       "min             -0.299831            -0.599662              0.003846  \n",
       "25%             -0.044269            -0.088538              0.020807  \n",
       "50%             -0.006686            -0.013373              0.029363  \n",
       "75%              0.035804             0.071608              0.042910  \n",
       "max              0.768245             1.536490              0.271085  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the data from Yahoo Finance (^SOX and ^VIX)\n",
    "start_date='2011-12-30'\n",
    "end_date='2023-01-11'\n",
    "\n",
    "data = yf.download('^SOX ^VIX', start=start_date, end=end_date, interval='1d')['Adj Close']\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data['^VIX^2'] = data['^VIX'].pow(2)\n",
    "\n",
    "# Calculate the log returns\n",
    "data['^SOX: Log_Returns'] = np.log(data['^SOX'].pct_change() + 1)\n",
    "data['^VIX: Log_Returns'] = np.log(data['^VIX'].pct_change() + 1)\n",
    "data['^VIX^2: Log_Returns'] = np.log(data['^VIX^2'].pct_change() + 1)\n",
    "\n",
    "data['^SOX: Next_Weekly_RV'] = np.sqrt((data['^SOX: Log_Returns']**2).rolling(5).sum()).shift(-6)\n",
    "data = data.dropna()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>^VIX^2</th>\n",
       "      <th>^SOX: Log_Returns</th>\n",
       "      <th>^VIX: Log_Returns</th>\n",
       "      <th>^VIX^2: Log_Returns</th>\n",
       "      <th>^SOX: Next_Weekly_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>368.421753</td>\n",
       "      <td>22.969999</td>\n",
       "      <td>527.620868</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>-0.018547</td>\n",
       "      <td>-0.037094</td>\n",
       "      <td>0.026753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>368.481720</td>\n",
       "      <td>22.219999</td>\n",
       "      <td>493.728369</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.033196</td>\n",
       "      <td>-0.066392</td>\n",
       "      <td>0.024366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>373.989044</td>\n",
       "      <td>21.480000</td>\n",
       "      <td>461.390380</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.067741</td>\n",
       "      <td>0.032283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>375.038544</td>\n",
       "      <td>20.629999</td>\n",
       "      <td>425.596865</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-0.040376</td>\n",
       "      <td>-0.080752</td>\n",
       "      <td>0.026164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>382.404968</td>\n",
       "      <td>21.070000</td>\n",
       "      <td>443.944887</td>\n",
       "      <td>0.019451</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>0.054788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>386.093170</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>428.076122</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>-0.018200</td>\n",
       "      <td>-0.036399</td>\n",
       "      <td>0.057642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-11</th>\n",
       "      <td>387.702423</td>\n",
       "      <td>21.049999</td>\n",
       "      <td>443.102468</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.017250</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.057041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-12</th>\n",
       "      <td>391.560547</td>\n",
       "      <td>20.469999</td>\n",
       "      <td>419.020872</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>-0.027940</td>\n",
       "      <td>-0.055880</td>\n",
       "      <td>0.052976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-13</th>\n",
       "      <td>383.284546</td>\n",
       "      <td>20.910000</td>\n",
       "      <td>437.228094</td>\n",
       "      <td>-0.021363</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>0.052897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-17</th>\n",
       "      <td>385.033691</td>\n",
       "      <td>22.200001</td>\n",
       "      <td>492.840034</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>0.020246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            ^SOX       ^VIX      ^VIX^2  ^SOX: Log_Returns  \\\n",
       "Date                                                               \n",
       "2012-01-03  368.421753  22.969999  527.620868           0.011350   \n",
       "2012-01-04  368.481720  22.219999  493.728369           0.000163   \n",
       "2012-01-05  373.989044  21.480000  461.390380           0.014835   \n",
       "2012-01-06  375.038544  20.629999  425.596865           0.002802   \n",
       "2012-01-09  382.404968  21.070000  443.944887           0.019451   \n",
       "2012-01-10  386.093170  20.690001  428.076122           0.009599   \n",
       "2012-01-11  387.702423  21.049999  443.102468           0.004159   \n",
       "2012-01-12  391.560547  20.469999  419.020872           0.009902   \n",
       "2012-01-13  383.284546  20.910000  437.228094          -0.021363   \n",
       "2012-01-17  385.033691  22.200001  492.840034           0.004553   \n",
       "\n",
       "Ticker      ^VIX: Log_Returns  ^VIX^2: Log_Returns  ^SOX: Next_Weekly_RV  \n",
       "Date                                                                      \n",
       "2012-01-03          -0.018547            -0.037094              0.026753  \n",
       "2012-01-04          -0.033196            -0.066392              0.024366  \n",
       "2012-01-05          -0.033871            -0.067741              0.032283  \n",
       "2012-01-06          -0.040376            -0.080752              0.026164  \n",
       "2012-01-09           0.021104             0.042208              0.054788  \n",
       "2012-01-10          -0.018200            -0.036399              0.057642  \n",
       "2012-01-11           0.017250             0.034500              0.057041  \n",
       "2012-01-12          -0.027940            -0.055880              0.052976  \n",
       "2012-01-13           0.021267             0.042534              0.052897  \n",
       "2012-01-17           0.059865             0.119730              0.020246  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>^VIX^2</th>\n",
       "      <th>^SOX: Log_Returns</th>\n",
       "      <th>^VIX: Log_Returns</th>\n",
       "      <th>^VIX^2: Log_Returns</th>\n",
       "      <th>^SOX: Next_Weekly_RV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-16</th>\n",
       "      <td>2636.100098</td>\n",
       "      <td>22.620001</td>\n",
       "      <td>511.664438</td>\n",
       "      <td>-0.009555</td>\n",
       "      <td>-0.009241</td>\n",
       "      <td>-0.018482</td>\n",
       "      <td>0.052457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-19</th>\n",
       "      <td>2599.860107</td>\n",
       "      <td>22.420000</td>\n",
       "      <td>502.656403</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>-0.008881</td>\n",
       "      <td>-0.017762</td>\n",
       "      <td>0.054155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-20</th>\n",
       "      <td>2583.639893</td>\n",
       "      <td>21.480000</td>\n",
       "      <td>461.390380</td>\n",
       "      <td>-0.006258</td>\n",
       "      <td>-0.042831</td>\n",
       "      <td>-0.085662</td>\n",
       "      <td>0.058801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-21</th>\n",
       "      <td>2644.500000</td>\n",
       "      <td>20.070000</td>\n",
       "      <td>402.804888</td>\n",
       "      <td>0.023283</td>\n",
       "      <td>-0.067896</td>\n",
       "      <td>-0.135792</td>\n",
       "      <td>0.040179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-22</th>\n",
       "      <td>2533.330078</td>\n",
       "      <td>21.969999</td>\n",
       "      <td>482.680870</td>\n",
       "      <td>-0.042947</td>\n",
       "      <td>0.090452</td>\n",
       "      <td>0.180903</td>\n",
       "      <td>0.042030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>2535.489990</td>\n",
       "      <td>20.870001</td>\n",
       "      <td>435.556935</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.051365</td>\n",
       "      <td>-0.102730</td>\n",
       "      <td>0.046591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>2490.169922</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>468.722483</td>\n",
       "      <td>-0.018036</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>0.073385</td>\n",
       "      <td>0.048492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>2453.489990</td>\n",
       "      <td>22.139999</td>\n",
       "      <td>490.179573</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>0.022380</td>\n",
       "      <td>0.044761</td>\n",
       "      <td>0.058023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>2534.949951</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>459.673623</td>\n",
       "      <td>0.032662</td>\n",
       "      <td>-0.032128</td>\n",
       "      <td>-0.064255</td>\n",
       "      <td>0.061054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>2532.110107</td>\n",
       "      <td>21.670000</td>\n",
       "      <td>469.588903</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>0.061138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             ^SOX       ^VIX      ^VIX^2  ^SOX: Log_Returns  \\\n",
       "Date                                                                \n",
       "2022-12-16  2636.100098  22.620001  511.664438          -0.009555   \n",
       "2022-12-19  2599.860107  22.420000  502.656403          -0.013843   \n",
       "2022-12-20  2583.639893  21.480000  461.390380          -0.006258   \n",
       "2022-12-21  2644.500000  20.070000  402.804888           0.023283   \n",
       "2022-12-22  2533.330078  21.969999  482.680870          -0.042947   \n",
       "2022-12-23  2535.489990  20.870001  435.556935           0.000852   \n",
       "2022-12-27  2490.169922  21.650000  468.722483          -0.018036   \n",
       "2022-12-28  2453.489990  22.139999  490.179573          -0.014839   \n",
       "2022-12-29  2534.949951  21.440001  459.673623           0.032662   \n",
       "2022-12-30  2532.110107  21.670000  469.588903          -0.001121   \n",
       "\n",
       "Ticker      ^VIX: Log_Returns  ^VIX^2: Log_Returns  ^SOX: Next_Weekly_RV  \n",
       "Date                                                                      \n",
       "2022-12-16          -0.009241            -0.018482              0.052457  \n",
       "2022-12-19          -0.008881            -0.017762              0.054155  \n",
       "2022-12-20          -0.042831            -0.085662              0.058801  \n",
       "2022-12-21          -0.067896            -0.135792              0.040179  \n",
       "2022-12-22           0.090452             0.180903              0.042030  \n",
       "2022-12-23          -0.051365            -0.102730              0.046591  \n",
       "2022-12-27           0.036693             0.073385              0.048492  \n",
       "2022-12-28           0.022380             0.044761              0.058023  \n",
       "2022-12-29          -0.032128            -0.064255              0.061054  \n",
       "2022-12-30           0.010670             0.021341              0.061138  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SOX', 'VIX', 'VIX2', 'SOX Log_Returns', 'VIX Log_Returns',\n",
       "       'VIX2 Log_Returns', 'SOX Next_Weekly_RV'],\n",
       "      dtype='object', name='Ticker')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the columns (delete special characters)\n",
    "data = data.rename(columns=lambda x: x.replace('^', '').replace(':', ''))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "1. Wisnorization\n",
    "2. Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>SOX</th>\n",
       "      <th>VIX</th>\n",
       "      <th>VIX2</th>\n",
       "      <th>SOX Log_Returns</th>\n",
       "      <th>VIX Log_Returns</th>\n",
       "      <th>VIX2 Log_Returns</th>\n",
       "      <th>SOX Next_Weekly_RV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>992.521460</td>\n",
       "      <td>17.854458</td>\n",
       "      <td>348.025046</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.021764</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>405.078887</td>\n",
       "      <td>7.057683</td>\n",
       "      <td>263.049386</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>0.072216</td>\n",
       "      <td>0.130178</td>\n",
       "      <td>0.021466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>351.280029</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>83.539606</td>\n",
       "      <td>-0.086366</td>\n",
       "      <td>-0.086366</td>\n",
       "      <td>-0.086366</td>\n",
       "      <td>0.003846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>616.449982</td>\n",
       "      <td>13.220000</td>\n",
       "      <td>174.768407</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>-0.044182</td>\n",
       "      <td>-0.086366</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1083.289978</td>\n",
       "      <td>15.935000</td>\n",
       "      <td>253.924248</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>-0.013373</td>\n",
       "      <td>0.029367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1418.020020</td>\n",
       "      <td>20.712499</td>\n",
       "      <td>429.007639</td>\n",
       "      <td>0.010203</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>0.071568</td>\n",
       "      <td>0.042919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1418.020020</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>1418.020020</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>0.768245</td>\n",
       "      <td>1.536490</td>\n",
       "      <td>0.271085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          SOX          VIX         VIX2  SOX Log_Returns  \\\n",
       "count   2768.000000  2768.000000  2768.000000      2768.000000   \n",
       "mean     992.521460    17.854458   348.025046         0.000749   \n",
       "std      405.078887     7.057683   263.049386         0.017797   \n",
       "min      351.280029     9.140000    83.539606        -0.086366   \n",
       "25%      616.449982    13.220000   174.768407        -0.008255   \n",
       "50%     1083.289978    15.935000   253.924248         0.001454   \n",
       "75%     1418.020020    20.712499   429.007639         0.010203   \n",
       "max     1418.020020    82.690002  1418.020020         0.105753   \n",
       "\n",
       "Ticker  VIX Log_Returns  VIX2 Log_Returns  SOX Next_Weekly_RV  \n",
       "count       2768.000000       2768.000000         2768.000000  \n",
       "mean           0.003759          0.021764            0.034444  \n",
       "std            0.072216          0.130178            0.021466  \n",
       "min           -0.086366         -0.086366            0.003846  \n",
       "25%           -0.044182         -0.086366            0.020800  \n",
       "50%           -0.006686         -0.013373            0.029367  \n",
       "75%            0.035784          0.071568            0.042919  \n",
       "max            0.768245          1.536490            0.271085  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform numerical data with wisnorization\n",
    "from scipy.stats.mstats import winsorize\n",
    "data = pd.DataFrame(winsorize(np.array(data), limits=[0.05, 0.05]), columns=data.columns, index=data.index)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>SOX</th>\n",
       "      <th>VIX</th>\n",
       "      <th>VIX2</th>\n",
       "      <th>SOX Log_Returns</th>\n",
       "      <th>VIX Log_Returns</th>\n",
       "      <th>VIX2 Log_Returns</th>\n",
       "      <th>SOX Next_Weekly_RV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "      <td>2768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.601123</td>\n",
       "      <td>0.118483</td>\n",
       "      <td>0.198194</td>\n",
       "      <td>0.453440</td>\n",
       "      <td>0.105458</td>\n",
       "      <td>0.066629</td>\n",
       "      <td>0.114497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.379735</td>\n",
       "      <td>0.095958</td>\n",
       "      <td>0.197117</td>\n",
       "      <td>0.092636</td>\n",
       "      <td>0.084501</td>\n",
       "      <td>0.080216</td>\n",
       "      <td>0.080325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.248580</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>0.406577</td>\n",
       "      <td>0.049361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.686212</td>\n",
       "      <td>0.092386</td>\n",
       "      <td>0.127679</td>\n",
       "      <td>0.457112</td>\n",
       "      <td>0.093235</td>\n",
       "      <td>0.044978</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157342</td>\n",
       "      <td>0.258878</td>\n",
       "      <td>0.502651</td>\n",
       "      <td>0.142930</td>\n",
       "      <td>0.097319</td>\n",
       "      <td>0.146210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          SOX          VIX         VIX2  SOX Log_Returns  \\\n",
       "count   2768.000000  2768.000000  2768.000000      2768.000000   \n",
       "mean       0.601123     0.118483     0.198194         0.453440   \n",
       "std        0.379735     0.095958     0.197117         0.092636   \n",
       "min        0.000000     0.000000     0.000000         0.000000   \n",
       "25%        0.248580     0.055472     0.068363         0.406577   \n",
       "50%        0.686212     0.092386     0.127679         0.457112   \n",
       "75%        1.000000     0.157342     0.258878         0.502651   \n",
       "max        1.000000     1.000000     1.000000         1.000000   \n",
       "\n",
       "Ticker  VIX Log_Returns  VIX2 Log_Returns  SOX Next_Weekly_RV  \n",
       "count       2768.000000       2768.000000         2768.000000  \n",
       "mean           0.105458          0.066629            0.114497  \n",
       "std            0.084501          0.080216            0.080325  \n",
       "min            0.000000          0.000000            0.000000  \n",
       "25%            0.049361          0.000000            0.063441  \n",
       "50%            0.093235          0.044978            0.095500  \n",
       "75%            0.142930          0.097319            0.146210  \n",
       "max            1.000000          1.000000            1.000000  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform numerical data with min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to transform the data (winsozation and min-max scaling)\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# def winsorize_data(data):\n",
    "#     return winsorize(np.array(data), limits=[0.025, 0.025])\n",
    "\n",
    "# def min_max_scale_data(data):\n",
    "#     return scaler.fit_transform(data)\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', FunctionTransformer(winsorize_data), data.columns),\n",
    "#         ('num2', FunctionTransformer(min_max_scale_data), data.columns)\n",
    "#     ])\n",
    "\n",
    "\n",
    "# data_tmp = preprocessor.fit_transform(data)\n",
    "# data = pd.DataFrame(data_tmp, columns=data.columns, index=data.index)\n",
    "# data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Dataset Preparation\n",
    "1. Training Data : 2012-2020\n",
    "2. Testing Data: 2021-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (training data from 2012 to 2020, test data from 2021 to 2022)\n",
    "data_train = data.loc['2012-01-01':'2020-12-31']\n",
    "data_test = data.loc['2021-01-01':'2022-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Attributes(X) and Target(Y)\n",
    "1. X \\\n",
    "    1.1 Index Value: ^SOX, ^VIX \\\n",
    "    1.2 Square Value: ^VIX^2 \\\n",
    "    1.3 Log Return: ^SOX, ^VIX, ^VIX^2\n",
    "    \n",
    "2. y: Weekly Relative Volatility of ^SOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X_base_train = data_train.drop(columns=['SOX Next_Weekly_RV'])\n",
    "y_train = data_train[['SOX Next_Weekly_RV']]\n",
    "X_base_test = data_test.drop(columns=['SOX Next_Weekly_RV'])\n",
    "y_test = data_test[['SOX Next_Weekly_RV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model Training and Performance\n",
    "1. Decesion Tree Regressor\n",
    "2. Linear Regression\n",
    "\n",
    "performance matrix\n",
    "1. Root Mean Square Error\n",
    "2. R-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "Best score: -0.018878200773558618\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree regressor model and use parameters from the grid search\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_base_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 5),\n",
    "    'min_samples_split': range(2, 5),\n",
    "    'min_samples_leaf': range(3, 8),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, n_jobs=-1, verbose=-1)\n",
    "grid_search.fit(X_base_train, y_train)\n",
    "\n",
    "# Report the best model parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.08272153325344428\n",
      "R2 score: -0.23359850684181271\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = grid_search.best_estimator_\n",
    "y_pred = model.predict(X_base_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_base_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.06626893137059825\n",
      "R2 score: 0.20830733958820336\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "y_pred = model.predict(X_base_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Model Training and Performance\n",
    "Hyperparamter tuning: Optuna\n",
    "\n",
    "Time series split = 5\n",
    "\n",
    "Objective function: Mean(R-Square)\n",
    "\n",
    "Performance matrix:\n",
    "1. Root Mean Square Error\n",
    "2. R-square\n",
    "\n",
    "Reference:\\\n",
    "https://forecastegy.com/posts/how-to-use-optuna-to-tune-lightgbm-hyperparameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"n_estimators\": 300,\n",
    "        \"verbosity\": -1,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**4),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 20),\n",
    "    }\n",
    "\n",
    "    r2_scores = np.array([])\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "        X_t, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_t, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        model.fit(X_t, y_t)\n",
    "        predictions = model.predict(X_val)\n",
    "        r2 = r2_score(y_val, predictions)\n",
    "        r2_scores = np.append(r2_scores, r2)\n",
    "    return r2_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-26 00:18:43,510] A new study created in memory with name: no-name-d953adba-f868-45f5-93e3-26908d3d279e\n",
      "[I 2024-04-26 00:18:43,831] Trial 0 finished with value: -0.06605924432557009 and parameters: {'learning_rate': 0.0017718736898429054, 'num_leaves': 13, 'subsample': 0.7404246796449283, 'colsample_bytree': 0.6871103661310634, 'min_data_in_leaf': 11}. Best is trial 0 with value: -0.06605924432557009.\n",
      "[I 2024-04-26 00:18:44,079] Trial 1 finished with value: 0.016499500241419596 and parameters: {'learning_rate': 0.00545266789333957, 'num_leaves': 9, 'subsample': 0.5017278005136825, 'colsample_bytree': 0.8227636911053671, 'min_data_in_leaf': 10}. Best is trial 1 with value: 0.016499500241419596.\n",
      "[I 2024-04-26 00:18:44,244] Trial 2 finished with value: 0.006545479975904311 and parameters: {'learning_rate': 0.037636393218236225, 'num_leaves': 4, 'subsample': 0.5600024232683103, 'colsample_bytree': 0.5346317785617414, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.016499500241419596.\n",
      "[I 2024-04-26 00:18:44,460] Trial 3 finished with value: -0.028412601536468608 and parameters: {'learning_rate': 0.003277175929647616, 'num_leaves': 7, 'subsample': 0.5971822209441716, 'colsample_bytree': 0.8037163132638728, 'min_data_in_leaf': 18}. Best is trial 1 with value: 0.016499500241419596.\n",
      "[I 2024-04-26 00:18:44,775] Trial 4 finished with value: 0.012899254523973114 and parameters: {'learning_rate': 0.004368576620796335, 'num_leaves': 11, 'subsample': 0.8746516638897737, 'colsample_bytree': 0.94701513696328, 'min_data_in_leaf': 12}. Best is trial 1 with value: 0.016499500241419596.\n",
      "[I 2024-04-26 00:18:44,961] Trial 5 finished with value: -0.017102410926735902 and parameters: {'learning_rate': 0.003080669774808001, 'num_leaves': 6, 'subsample': 0.6423592697329586, 'colsample_bytree': 0.843927776486418, 'min_data_in_leaf': 10}. Best is trial 1 with value: 0.016499500241419596.\n",
      "[I 2024-04-26 00:18:45,331] Trial 6 finished with value: -0.11174497223729837 and parameters: {'learning_rate': 0.0011370893982348062, 'num_leaves': 15, 'subsample': 0.9205957446214541, 'colsample_bytree': 0.9555934660293076, 'min_data_in_leaf': 19}. Best is trial 1 with value: 0.016499500241419596.\n",
      "[I 2024-04-26 00:18:45,573] Trial 7 finished with value: 0.019081363180087595 and parameters: {'learning_rate': 0.010116149625960177, 'num_leaves': 10, 'subsample': 0.8445800653156028, 'colsample_bytree': 0.5744567683446706, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.019081363180087595.\n",
      "[I 2024-04-26 00:18:45,947] Trial 8 finished with value: -0.08906208276658578 and parameters: {'learning_rate': 0.0014862105939464272, 'num_leaves': 15, 'subsample': 0.9732516969193996, 'colsample_bytree': 0.9673439637458714, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.019081363180087595.\n",
      "[I 2024-04-26 00:18:46,276] Trial 9 finished with value: 0.016210016100361657 and parameters: {'learning_rate': 0.004811349185567149, 'num_leaves': 13, 'subsample': 0.580674639642594, 'colsample_bytree': 0.940604937991459, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.019081363180087595.\n",
      "[I 2024-04-26 00:18:46,392] Trial 10 finished with value: -0.03244813925693961 and parameters: {'learning_rate': 0.02538286939582868, 'num_leaves': 2, 'subsample': 0.8093799636739113, 'colsample_bytree': 0.5244788058794587, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.019081363180087595.\n",
      "[I 2024-04-26 00:18:46,658] Trial 11 finished with value: -0.009243721552859952 and parameters: {'learning_rate': 0.01171258862235361, 'num_leaves': 9, 'subsample': 0.7093678596821825, 'colsample_bytree': 0.6659175759113947, 'min_data_in_leaf': 5}. Best is trial 7 with value: 0.019081363180087595.\n",
      "[I 2024-04-26 00:18:46,941] Trial 12 finished with value: -0.17861106758125622 and parameters: {'learning_rate': 0.09846007062506526, 'num_leaves': 9, 'subsample': 0.5024815744029194, 'colsample_bytree': 0.6885542974504125, 'min_data_in_leaf': 3}. Best is trial 7 with value: 0.019081363180087595.\n",
      "[I 2024-04-26 00:18:47,231] Trial 13 finished with value: 0.037521593871753536 and parameters: {'learning_rate': 0.01007214747532483, 'num_leaves': 11, 'subsample': 0.8233685397211162, 'colsample_bytree': 0.5941313082927642, 'min_data_in_leaf': 14}. Best is trial 13 with value: 0.037521593871753536.\n",
      "[I 2024-04-26 00:18:47,539] Trial 14 finished with value: 0.039324654297330675 and parameters: {'learning_rate': 0.011286489987728092, 'num_leaves': 12, 'subsample': 0.8220860410037983, 'colsample_bytree': 0.5930602589317621, 'min_data_in_leaf': 14}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:47,846] Trial 15 finished with value: 0.03704302841115363 and parameters: {'learning_rate': 0.020320117624203448, 'num_leaves': 12, 'subsample': 0.7802362064409525, 'colsample_bytree': 0.6184042280765664, 'min_data_in_leaf': 14}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:48,192] Trial 16 finished with value: 0.019395677824059755 and parameters: {'learning_rate': 0.01606762914258835, 'num_leaves': 16, 'subsample': 0.6841535483847319, 'colsample_bytree': 0.6200708185099678, 'min_data_in_leaf': 16}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:48,410] Trial 17 finished with value: 0.021915490380945778 and parameters: {'learning_rate': 0.04706527481872367, 'num_leaves': 7, 'subsample': 0.996322238535535, 'colsample_bytree': 0.7479063634782888, 'min_data_in_leaf': 13}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:48,708] Trial 18 finished with value: 0.018483057004803616 and parameters: {'learning_rate': 0.00798789175432362, 'num_leaves': 13, 'subsample': 0.889780182131735, 'colsample_bytree': 0.5077067489747811, 'min_data_in_leaf': 17}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:49,011] Trial 19 finished with value: 0.035240564639185304 and parameters: {'learning_rate': 0.007590546139723609, 'num_leaves': 11, 'subsample': 0.803214822836576, 'colsample_bytree': 0.5902654423412009, 'min_data_in_leaf': 14}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:49,243] Trial 20 finished with value: 0.008575444342911154 and parameters: {'learning_rate': 0.04183371772876727, 'num_leaves': 7, 'subsample': 0.7523103426957681, 'colsample_bytree': 0.7488393655158208, 'min_data_in_leaf': 16}. Best is trial 14 with value: 0.039324654297330675.\n",
      "[I 2024-04-26 00:18:49,556] Trial 21 finished with value: 0.04014229296985348 and parameters: {'learning_rate': 0.019600400875542115, 'num_leaves': 12, 'subsample': 0.7950251238095289, 'colsample_bytree': 0.6337109534502311, 'min_data_in_leaf': 14}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:49,845] Trial 22 finished with value: 0.02694171784790993 and parameters: {'learning_rate': 0.014291511181620963, 'num_leaves': 11, 'subsample': 0.83765248337327, 'colsample_bytree': 0.6531156280709098, 'min_data_in_leaf': 20}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:50,147] Trial 23 finished with value: 0.019093232709185858 and parameters: {'learning_rate': 0.025923153239396566, 'num_leaves': 14, 'subsample': 0.9298006287024341, 'colsample_bytree': 0.5742795677398433, 'min_data_in_leaf': 13}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:50,468] Trial 24 finished with value: 0.036510522094948164 and parameters: {'learning_rate': 0.00801759531444014, 'num_leaves': 12, 'subsample': 0.7661810010907564, 'colsample_bytree': 0.7168578868409781, 'min_data_in_leaf': 12}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:50,724] Trial 25 finished with value: 0.03529036252288893 and parameters: {'learning_rate': 0.019931023388671424, 'num_leaves': 10, 'subsample': 0.8406284956159323, 'colsample_bytree': 0.6297978175391498, 'min_data_in_leaf': 15}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:51,053] Trial 26 finished with value: -0.033385238478859436 and parameters: {'learning_rate': 0.0936049794638654, 'num_leaves': 14, 'subsample': 0.6864269123648936, 'colsample_bytree': 0.5548440654480226, 'min_data_in_leaf': 17}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:51,355] Trial 27 finished with value: -0.005267933442041217 and parameters: {'learning_rate': 0.06544177019959725, 'num_leaves': 12, 'subsample': 0.7976009024776773, 'colsample_bytree': 0.6087715090857891, 'min_data_in_leaf': 12}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:51,628] Trial 28 finished with value: 0.015558242938755584 and parameters: {'learning_rate': 0.013542496802028913, 'num_leaves': 10, 'subsample': 0.8812128840662276, 'colsample_bytree': 0.5000866734979188, 'min_data_in_leaf': 8}. Best is trial 21 with value: 0.04014229296985348.\n",
      "[I 2024-04-26 00:18:51,961] Trial 29 finished with value: -0.05232513993429513 and parameters: {'learning_rate': 0.002107304416858263, 'num_leaves': 14, 'subsample': 0.9299896523118473, 'colsample_bytree': 0.6807630134754534, 'min_data_in_leaf': 11}. Best is trial 21 with value: 0.04014229296985348.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_base_train, y_train), n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 2265, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 0.102259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=14, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=14\n",
      "RMSE: 0.08066431152617606\n",
      "R2 score: -0.17300414522294805\n"
     ]
    }
   ],
   "source": [
    "# Create a LightGBM model with the best parameters\n",
    "best_params = study.best_params\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "model.fit(X_base_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "y_pred = model.predict(X_base_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "1. log of lag weekly realized volatility\n",
    "2. square of lag weekly realized volatility\n",
    "3. log of VIX\n",
    "4. log of past 5 days VIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOX Next_Weekly_RV Lag 1</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 1</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 2</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 2</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 3</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 3</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 4</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 4</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 5</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 5</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 6</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 6</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 7</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 7</th>\n",
       "      <th>SOX Next_Weekly_RV Lag 8</th>\n",
       "      <th>SOX Weekly_Squared_RV Lag 8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>-2.456686</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>-2.566743</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>-2.456686</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>-2.240444</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>-2.566743</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>-2.456686</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>-2.482727</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>-2.240444</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>-2.566743</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>-2.456686</td>\n",
       "      <td>0.007348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>-1.945723</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>-1.995423</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>-1.581629</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>-1.669951</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>-1.704288</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>-1.731182</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>-1.712806</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>-1.718549</td>\n",
       "      <td>0.032158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-1.832889</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>-1.945723</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>-1.995423</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>-1.581629</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>-1.669951</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>-1.704288</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>-1.731182</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>-1.712806</td>\n",
       "      <td>0.032529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-1.789374</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>-1.832889</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>-1.945723</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>-1.995423</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>-1.581629</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>-1.669951</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>-1.704288</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>-1.731182</td>\n",
       "      <td>0.031356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>-1.595885</td>\n",
       "      <td>0.041099</td>\n",
       "      <td>-1.789374</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>-1.832889</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>-1.945723</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>-1.995423</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>-1.581629</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>-1.669951</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>-1.704288</td>\n",
       "      <td>0.033088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-1.541444</td>\n",
       "      <td>0.045827</td>\n",
       "      <td>-1.595885</td>\n",
       "      <td>0.041099</td>\n",
       "      <td>-1.789374</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>-1.832889</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>-1.945723</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>-1.995423</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>-1.581629</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>-1.669951</td>\n",
       "      <td>0.035440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SOX Next_Weekly_RV Lag 1  SOX Weekly_Squared_RV Lag 1  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                 -2.456686                     0.007348   \n",
       "2012-01-05                 -2.566743                     0.005896   \n",
       "2012-01-06                 -2.240444                     0.011323   \n",
       "2012-01-09                 -2.482727                     0.006975   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.945723                     0.020416   \n",
       "2022-12-27                 -1.832889                     0.025584   \n",
       "2022-12-28                 -1.789374                     0.027911   \n",
       "2022-12-29                 -1.595885                     0.041099   \n",
       "2022-12-30                 -1.541444                     0.045827   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 2  SOX Weekly_Squared_RV Lag 2  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                       NaN                          NaN   \n",
       "2012-01-05                 -2.456686                     0.007348   \n",
       "2012-01-06                 -2.566743                     0.005896   \n",
       "2012-01-09                 -2.240444                     0.011323   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.995423                     0.018484   \n",
       "2022-12-27                 -1.945723                     0.020416   \n",
       "2022-12-28                 -1.832889                     0.025584   \n",
       "2022-12-29                 -1.789374                     0.027911   \n",
       "2022-12-30                 -1.595885                     0.041099   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 3  SOX Weekly_Squared_RV Lag 3  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                       NaN                          NaN   \n",
       "2012-01-05                       NaN                          NaN   \n",
       "2012-01-06                 -2.456686                     0.007348   \n",
       "2012-01-09                 -2.566743                     0.005896   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.581629                     0.042288   \n",
       "2022-12-27                 -1.995423                     0.018484   \n",
       "2022-12-28                 -1.945723                     0.020416   \n",
       "2022-12-29                 -1.832889                     0.025584   \n",
       "2022-12-30                 -1.789374                     0.027911   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 4  SOX Weekly_Squared_RV Lag 4  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                       NaN                          NaN   \n",
       "2012-01-05                       NaN                          NaN   \n",
       "2012-01-06                       NaN                          NaN   \n",
       "2012-01-09                 -2.456686                     0.007348   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.669951                     0.035440   \n",
       "2022-12-27                 -1.581629                     0.042288   \n",
       "2022-12-28                 -1.995423                     0.018484   \n",
       "2022-12-29                 -1.945723                     0.020416   \n",
       "2022-12-30                 -1.832889                     0.025584   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 5  SOX Weekly_Squared_RV Lag 5  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                       NaN                          NaN   \n",
       "2012-01-05                       NaN                          NaN   \n",
       "2012-01-06                       NaN                          NaN   \n",
       "2012-01-09                       NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.704288                     0.033088   \n",
       "2022-12-27                 -1.669951                     0.035440   \n",
       "2022-12-28                 -1.581629                     0.042288   \n",
       "2022-12-29                 -1.995423                     0.018484   \n",
       "2022-12-30                 -1.945723                     0.020416   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 6  SOX Weekly_Squared_RV Lag 6  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                       NaN                          NaN   \n",
       "2012-01-05                       NaN                          NaN   \n",
       "2012-01-06                       NaN                          NaN   \n",
       "2012-01-09                       NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.731182                     0.031356   \n",
       "2022-12-27                 -1.704288                     0.033088   \n",
       "2022-12-28                 -1.669951                     0.035440   \n",
       "2022-12-29                 -1.581629                     0.042288   \n",
       "2022-12-30                 -1.995423                     0.018484   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 7  SOX Weekly_Squared_RV Lag 7  \\\n",
       "Date                                                                \n",
       "2012-01-03                       NaN                          NaN   \n",
       "2012-01-04                       NaN                          NaN   \n",
       "2012-01-05                       NaN                          NaN   \n",
       "2012-01-06                       NaN                          NaN   \n",
       "2012-01-09                       NaN                          NaN   \n",
       "...                              ...                          ...   \n",
       "2022-12-23                 -1.712806                     0.032529   \n",
       "2022-12-27                 -1.731182                     0.031356   \n",
       "2022-12-28                 -1.704288                     0.033088   \n",
       "2022-12-29                 -1.669951                     0.035440   \n",
       "2022-12-30                 -1.581629                     0.042288   \n",
       "\n",
       "            SOX Next_Weekly_RV Lag 8  SOX Weekly_Squared_RV Lag 8  \n",
       "Date                                                               \n",
       "2012-01-03                       NaN                          NaN  \n",
       "2012-01-04                       NaN                          NaN  \n",
       "2012-01-05                       NaN                          NaN  \n",
       "2012-01-06                       NaN                          NaN  \n",
       "2012-01-09                       NaN                          NaN  \n",
       "...                              ...                          ...  \n",
       "2022-12-23                 -1.718549                     0.032158  \n",
       "2022-12-27                 -1.712806                     0.032529  \n",
       "2022-12-28                 -1.731182                     0.031356  \n",
       "2022-12-29                 -1.704288                     0.033088  \n",
       "2022-12-30                 -1.669951                     0.035440  \n",
       "\n",
       "[2768 rows x 16 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lag = pd.DataFrame()\n",
    "for i in range(1, 9):\n",
    "    # Add new columns name 'SOX Next_Weekly_RV Lag 1', 'SOX Next_Weekly_RV Lag 2', 'SOX Next_Weekly_RV Lag 3', 'SOX Next_Weekly_RV Lag 4', 'SOX Next_Weekly_RV Lag 5', 'SOX Next_Weekly_RV Lag 6', 'SOX Next_Weekly_RV Lag 7', 'SOX Next_Weekly_RV Lag 8'\n",
    "    data_lag[f'SOX Next_Weekly_RV Lag {i}'] = data['SOX Next_Weekly_RV'].shift(i)\n",
    "    # Add new columns name 'SOX Next_Weekly_Log_RV Lag 1', 'SOX Next_Weekly_Log_RV Lag 2', 'SOX Next_Weekly_Log_RV Lag 3', 'SOX Next_Weekly_Log_RV Lag 4', 'SOX Next_Weekly_Log_RV Lag 5', 'SOX Next_Weekly_Log_RV Lag 6', 'SOX Next_Weekly_Log_RV Lag 7', 'SOX Next_Weekly_Log_RV Lag 8'\n",
    "    data_lag[f'SOX Next_Weekly_RV Lag {i}'] = np.log(data['SOX Next_Weekly_RV']).shift(i)\n",
    "    # Add new columns name 'SOX Next_Weekly_Squared_RV Lag 1', 'SOX Next_Weekly_Squared_RV Lag 2', 'SOX Next_Weekly_Squared_RV Lag 3', 'SOX Next_Weekly_Squared_RV Lag 4', 'SOX Next_Weekly_Squared_RV Lag 5', 'SOX Next_Weekly_Squared_RV Lag 6', 'SOX Next_Weekly_Squared_RV Lag 7', 'SOX Next_Weekly_Squared_RV Lag 8'\n",
    "    data_lag[f'SOX Weekly_Squared_RV Lag {i}'] = (data['SOX Next_Weekly_RV']**2).shift(i)\n",
    "\n",
    "data_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data+lagged data into training and test sets (training data from 2012 to 2020, test data from 2021 to 2022)\n",
    "data_train = pd.concat([data, data_lag], axis=1).loc['2012-01-01':'2020-12-31']\n",
    "data_test = pd.concat([data, data_lag], axis=1).loc['2021-01-01':'2022-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y for the new features\n",
    "X_lags_train = data_train.drop(columns=['SOX Next_Weekly_RV'])\n",
    "y_lags_train= data_train[['SOX Next_Weekly_RV']]\n",
    "X_lags_test = data_test.drop(columns=['SOX Next_Weekly_RV'])\n",
    "y_lags_test = data_test[['SOX Next_Weekly_RV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-26 00:47:17,620] A new study created in memory with name: no-name-9738fe87-3d85-433d-8e2b-ea44cb9aeb3b\n",
      "[I 2024-04-26 00:47:18,283] Trial 0 finished with value: 0.6551046973585504 and parameters: {'learning_rate': 0.022668538613565752, 'num_leaves': 10, 'subsample': 0.623982198385168, 'colsample_bytree': 0.6206240484663136, 'min_data_in_leaf': 3}. Best is trial 0 with value: 0.6551046973585504.\n",
      "[I 2024-04-26 00:47:18,712] Trial 1 finished with value: 0.4600079669898693 and parameters: {'learning_rate': 0.003093697934551272, 'num_leaves': 6, 'subsample': 0.8678871095032297, 'colsample_bytree': 0.9858789166913651, 'min_data_in_leaf': 16}. Best is trial 0 with value: 0.6551046973585504.\n",
      "[I 2024-04-26 00:47:19,355] Trial 2 finished with value: 0.6237246528416278 and parameters: {'learning_rate': 0.027909987888205208, 'num_leaves': 11, 'subsample': 0.6630327075115752, 'colsample_bytree': 0.8018155558203652, 'min_data_in_leaf': 1}. Best is trial 0 with value: 0.6551046973585504.\n",
      "[I 2024-04-26 00:47:19,864] Trial 3 finished with value: 0.17604867604650248 and parameters: {'learning_rate': 0.0011518444106981157, 'num_leaves': 9, 'subsample': 0.9508675613694408, 'colsample_bytree': 0.7388806605760192, 'min_data_in_leaf': 9}. Best is trial 0 with value: 0.6551046973585504.\n",
      "[I 2024-04-26 00:47:20,729] Trial 4 finished with value: 0.2932206069347653 and parameters: {'learning_rate': 0.0017190508018799806, 'num_leaves': 14, 'subsample': 0.9310679819045579, 'colsample_bytree': 0.9630651356807377, 'min_data_in_leaf': 3}. Best is trial 0 with value: 0.6551046973585504.\n",
      "[I 2024-04-26 00:47:21,483] Trial 5 finished with value: 0.37445116693370695 and parameters: {'learning_rate': 0.0022778633100365916, 'num_leaves': 15, 'subsample': 0.5397313195014211, 'colsample_bytree': 0.6261127127908581, 'min_data_in_leaf': 3}. Best is trial 0 with value: 0.6551046973585504.\n",
      "[I 2024-04-26 00:47:22,195] Trial 6 finished with value: 0.6702744510586583 and parameters: {'learning_rate': 0.030098641609037885, 'num_leaves': 12, 'subsample': 0.8872099595493005, 'colsample_bytree': 0.7995103347681081, 'min_data_in_leaf': 9}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:23,027] Trial 7 finished with value: 0.6654535745849463 and parameters: {'learning_rate': 0.009895046532526125, 'num_leaves': 14, 'subsample': 0.9092538943928022, 'colsample_bytree': 0.9591269565660043, 'min_data_in_leaf': 11}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:23,786] Trial 8 finished with value: 0.6527746114207706 and parameters: {'learning_rate': 0.048942145489201866, 'num_leaves': 16, 'subsample': 0.8302877132700356, 'colsample_bytree': 0.8348535037537885, 'min_data_in_leaf': 15}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:24,325] Trial 9 finished with value: 0.6499609334988747 and parameters: {'learning_rate': 0.0510816694312483, 'num_leaves': 13, 'subsample': 0.8662157767694534, 'colsample_bytree': 0.5630621574648611, 'min_data_in_leaf': 9}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:24,678] Trial 10 finished with value: 0.6298404973361796 and parameters: {'learning_rate': 0.008943010460671894, 'num_leaves': 5, 'subsample': 0.7508988851314888, 'colsample_bytree': 0.7293905210990038, 'min_data_in_leaf': 19}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:24,865] Trial 11 finished with value: 0.5474558617696893 and parameters: {'learning_rate': 0.009539184320253424, 'num_leaves': 2, 'subsample': 0.9705068170488643, 'colsample_bytree': 0.8950359122896074, 'min_data_in_leaf': 12}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:25,494] Trial 12 finished with value: 0.6421155771589662 and parameters: {'learning_rate': 0.095160050649046, 'num_leaves': 12, 'subsample': 0.7927798044652115, 'colsample_bytree': 0.8859205484117127, 'min_data_in_leaf': 11}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:26,087] Trial 13 finished with value: 0.6009517260024889 and parameters: {'learning_rate': 0.005339232830535589, 'num_leaves': 9, 'subsample': 0.8988663974949049, 'colsample_bytree': 0.9031815094095982, 'min_data_in_leaf': 6}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:26,735] Trial 14 finished with value: 0.6701641754197215 and parameters: {'learning_rate': 0.020586463884039313, 'num_leaves': 13, 'subsample': 0.7001469909581305, 'colsample_bytree': 0.688015427363569, 'min_data_in_leaf': 7}. Best is trial 6 with value: 0.6702744510586583.\n",
      "[I 2024-04-26 00:47:27,174] Trial 15 finished with value: 0.6857939071059878 and parameters: {'learning_rate': 0.023020427309475382, 'num_leaves': 7, 'subsample': 0.7042795004073896, 'colsample_bytree': 0.6746909604416835, 'min_data_in_leaf': 6}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:27,614] Trial 16 finished with value: 0.6733375077644937 and parameters: {'learning_rate': 0.040392529183830204, 'num_leaves': 7, 'subsample': 0.5932542153851081, 'colsample_bytree': 0.6673601138378717, 'min_data_in_leaf': 6}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:27,961] Trial 17 finished with value: 0.6464183141695659 and parameters: {'learning_rate': 0.08961667919144428, 'num_leaves': 6, 'subsample': 0.5640317350106961, 'colsample_bytree': 0.5047197838063155, 'min_data_in_leaf': 6}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:28,414] Trial 18 finished with value: 0.678840483164946 and parameters: {'learning_rate': 0.015528637781760283, 'num_leaves': 7, 'subsample': 0.5933185613981319, 'colsample_bytree': 0.6667161078842592, 'min_data_in_leaf': 5}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:28,689] Trial 19 finished with value: 0.6467119929990712 and parameters: {'learning_rate': 0.015851224498929038, 'num_leaves': 4, 'subsample': 0.5149997644207516, 'colsample_bytree': 0.5642971263673847, 'min_data_in_leaf': 1}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:29,191] Trial 20 finished with value: 0.5907349283600265 and parameters: {'learning_rate': 0.005479409461005294, 'num_leaves': 8, 'subsample': 0.7218324499323607, 'colsample_bytree': 0.6865320319508634, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:29,611] Trial 21 finished with value: 0.6687548301456069 and parameters: {'learning_rate': 0.04236902111020619, 'num_leaves': 7, 'subsample': 0.6143971604704846, 'colsample_bytree': 0.6691612082883682, 'min_data_in_leaf': 5}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:29,870] Trial 22 finished with value: 0.6497590343314673 and parameters: {'learning_rate': 0.015418256119237181, 'num_leaves': 3, 'subsample': 0.5963104905721365, 'colsample_bytree': 0.6383964670977075, 'min_data_in_leaf': 8}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:30,298] Trial 23 finished with value: 0.6562519754509007 and parameters: {'learning_rate': 0.0644414834253341, 'num_leaves': 7, 'subsample': 0.6682052744651962, 'colsample_bytree': 0.581694310266665, 'min_data_in_leaf': 4}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:30,708] Trial 24 finished with value: 0.6717343541591828 and parameters: {'learning_rate': 0.013808447996203666, 'num_leaves': 5, 'subsample': 0.5837855652800698, 'colsample_bytree': 0.712611411406217, 'min_data_in_leaf': 5}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:31,210] Trial 25 finished with value: 0.6748287970621847 and parameters: {'learning_rate': 0.03225328696961305, 'num_leaves': 8, 'subsample': 0.6535112963117455, 'colsample_bytree': 0.7734885906502755, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:31,829] Trial 26 finished with value: 0.6658668142650138 and parameters: {'learning_rate': 0.03277147232804335, 'num_leaves': 9, 'subsample': 0.6627329173530158, 'colsample_bytree': 0.7516016331923259, 'min_data_in_leaf': 7}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:32,313] Trial 27 finished with value: 0.5980297677865724 and parameters: {'learning_rate': 0.005563368874444431, 'num_leaves': 8, 'subsample': 0.7542485531021864, 'colsample_bytree': 0.7774748617570537, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:32,914] Trial 28 finished with value: 0.676194795223858 and parameters: {'learning_rate': 0.019708364962189417, 'num_leaves': 10, 'subsample': 0.6402611537680244, 'colsample_bytree': 0.8451868817105752, 'min_data_in_leaf': 10}. Best is trial 15 with value: 0.6857939071059878.\n",
      "[I 2024-04-26 00:47:33,527] Trial 29 finished with value: 0.676022474626947 and parameters: {'learning_rate': 0.020940966423552244, 'num_leaves': 10, 'subsample': 0.7051158982932463, 'colsample_bytree': 0.8497341306648755, 'min_data_in_leaf': 10}. Best is trial 15 with value: 0.6857939071059878.\n"
     ]
    }
   ],
   "source": [
    "# Train a LightGBM model with the new features\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_lags_train, y_lags_train), n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5610\n",
      "[LightGBM] [Info] Number of data points in the train set: 2265, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.102259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "RMSE: 0.03906117370862857\n",
      "R2 score: 0.724940112132169\n"
     ]
    }
   ],
   "source": [
    "# Create a LightGBM model with the best parameters\n",
    "best_params = study.best_params\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "model.fit(X_lags_train, y_lags_train)\n",
    "\n",
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "y_pred = model.predict(X_lags_test)\n",
    "mse = mean_squared_error(y_lags_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_lags_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LiaoYF\\anaconda3\\envs\\FT5005MachineLearningEnv\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIX Log</th>\n",
       "      <th>VIX Log 5 Day Mean</th>\n",
       "      <th>VIX Log 5 Day Sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>-1.671125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>-1.726881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>-1.785120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>-1.856488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>-1.818909</td>\n",
       "      <td>-1.769521</td>\n",
       "      <td>-0.160083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>-1.835816</td>\n",
       "      <td>-1.794728</td>\n",
       "      <td>-0.185290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-1.771437</td>\n",
       "      <td>-1.807408</td>\n",
       "      <td>-0.197970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-1.733016</td>\n",
       "      <td>-1.796530</td>\n",
       "      <td>-0.187092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>-1.788366</td>\n",
       "      <td>-1.774319</td>\n",
       "      <td>-0.164881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-1.769840</td>\n",
       "      <td>-1.779141</td>\n",
       "      <td>-0.169703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             VIX Log  VIX Log 5 Day Mean  VIX Log 5 Day Sum\n",
       "Date                                                       \n",
       "2012-01-03 -1.671125                 NaN                NaN\n",
       "2012-01-04 -1.726881                 NaN                NaN\n",
       "2012-01-05 -1.785120                 NaN                NaN\n",
       "2012-01-06 -1.856488                 NaN                NaN\n",
       "2012-01-09 -1.818909           -1.769521          -0.160083\n",
       "...              ...                 ...                ...\n",
       "2022-12-23 -1.835816           -1.794728          -0.185290\n",
       "2022-12-27 -1.771437           -1.807408          -0.197970\n",
       "2022-12-28 -1.733016           -1.796530          -0.187092\n",
       "2022-12-29 -1.788366           -1.774319          -0.164881\n",
       "2022-12-30 -1.769840           -1.779141          -0.169703\n",
       "\n",
       "[2768 rows x 3 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe to store new features for Lof of VIX and Log of past 5-day VIX\n",
    "data_VIX = pd.DataFrame()\n",
    "data_VIX['VIX Log'] = np.log(data['VIX'])\n",
    "data_VIX['VIX Log 5 Day Mean'] = np.log(data['VIX'].rolling(5).mean())\n",
    "data_VIX['VIX Log 5 Day Sum'] = np.log(data['VIX'].rolling(5).sum())\n",
    "\n",
    "data_VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data+VIX data into training and test sets (training data from 2012 to 2020, test data from 2021 to 2022)\n",
    "data_train = pd.concat([data, data_VIX], axis=1).loc['2012-01-01':'2020-12-31']\n",
    "data_test = pd.concat([data, data_VIX], axis=1).loc['2021-01-01':'2022-12-31']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y for the new features\n",
    "X_VIX_train = data_train.drop(columns=['SOX Next_Weekly_RV'])\n",
    "y_VIX_train = data_train[['SOX Next_Weekly_RV']]\n",
    "X_VIX_test = data_test.drop(columns=['SOX Next_Weekly_RV'])\n",
    "y_VIX_test = data_test[['SOX Next_Weekly_RV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-26 00:48:44,040] A new study created in memory with name: no-name-60087f9f-1c52-4700-a687-2c430f9ea9e7\n",
      "[I 2024-04-26 00:48:44,392] Trial 0 finished with value: 0.007601738357451771 and parameters: {'learning_rate': 0.007012070948974538, 'num_leaves': 10, 'subsample': 0.6551787377757826, 'colsample_bytree': 0.5179581033481819, 'min_data_in_leaf': 3}. Best is trial 0 with value: 0.007601738357451771.\n",
      "[I 2024-04-26 00:48:44,742] Trial 1 finished with value: -0.047477322175287995 and parameters: {'learning_rate': 0.03866002500358503, 'num_leaves': 11, 'subsample': 0.8684870435832603, 'colsample_bytree': 0.6559077202363865, 'min_data_in_leaf': 8}. Best is trial 0 with value: 0.007601738357451771.\n",
      "[I 2024-04-26 00:48:44,878] Trial 2 finished with value: 0.03367154351167181 and parameters: {'learning_rate': 0.010984039586005977, 'num_leaves': 2, 'subsample': 0.6812657763223308, 'colsample_bytree': 0.6110608173685024, 'min_data_in_leaf': 2}. Best is trial 2 with value: 0.03367154351167181.\n",
      "[I 2024-04-26 00:48:45,322] Trial 3 finished with value: 0.0033093724060030416 and parameters: {'learning_rate': 0.014170275333584644, 'num_leaves': 16, 'subsample': 0.7953134654138909, 'colsample_bytree': 0.5810096938093248, 'min_data_in_leaf': 8}. Best is trial 2 with value: 0.03367154351167181.\n",
      "[I 2024-04-26 00:48:45,544] Trial 4 finished with value: -0.07763887929197008 and parameters: {'learning_rate': 0.0017525187388494686, 'num_leaves': 4, 'subsample': 0.5183783838905047, 'colsample_bytree': 0.9153021407533173, 'min_data_in_leaf': 18}. Best is trial 2 with value: 0.03367154351167181.\n",
      "[I 2024-04-26 00:48:45,926] Trial 5 finished with value: -0.010642433405315722 and parameters: {'learning_rate': 0.03808881142519361, 'num_leaves': 14, 'subsample': 0.59651963591001, 'colsample_bytree': 0.8444687714795146, 'min_data_in_leaf': 18}. Best is trial 2 with value: 0.03367154351167181.\n",
      "[I 2024-04-26 00:48:46,285] Trial 6 finished with value: -0.008227952167689123 and parameters: {'learning_rate': 0.007227239968147955, 'num_leaves': 14, 'subsample': 0.9810298150849952, 'colsample_bytree': 0.5122595627475185, 'min_data_in_leaf': 4}. Best is trial 2 with value: 0.03367154351167181.\n",
      "[I 2024-04-26 00:48:46,560] Trial 7 finished with value: 0.0488057480996696 and parameters: {'learning_rate': 0.007197502593472692, 'num_leaves': 10, 'subsample': 0.9692304218273222, 'colsample_bytree': 0.6978373948167198, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:46,718] Trial 8 finished with value: 0.027689079063210144 and parameters: {'learning_rate': 0.018280436117050495, 'num_leaves': 3, 'subsample': 0.5094132524652812, 'colsample_bytree': 0.6904703653147051, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:47,043] Trial 9 finished with value: 0.0059900044774755965 and parameters: {'learning_rate': 0.00416292696746253, 'num_leaves': 10, 'subsample': 0.6386278618301346, 'colsample_bytree': 0.7323755731979129, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:47,307] Trial 10 finished with value: -0.09399199977566228 and parameters: {'learning_rate': 0.001006238576307271, 'num_leaves': 7, 'subsample': 0.9935176344331615, 'colsample_bytree': 0.8064976721372409, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:47,557] Trial 11 finished with value: 0.011479546309122846 and parameters: {'learning_rate': 0.0037312588645305148, 'num_leaves': 6, 'subsample': 0.75081435434797, 'colsample_bytree': 0.6217888841457033, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:47,839] Trial 12 finished with value: -0.012701850216587674 and parameters: {'learning_rate': 0.016374854927937523, 'num_leaves': 7, 'subsample': 0.8705586394395105, 'colsample_bytree': 0.7623420929074443, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:48,072] Trial 13 finished with value: 0.02515321314763854 and parameters: {'learning_rate': 0.07116427414734956, 'num_leaves': 5, 'subsample': 0.7171356939952258, 'colsample_bytree': 0.5860954771767214, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:48,222] Trial 14 finished with value: -0.045483574584213815 and parameters: {'learning_rate': 0.003662671977307499, 'num_leaves': 2, 'subsample': 0.8949094523986509, 'colsample_bytree': 0.6982623075370248, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:48,603] Trial 15 finished with value: 0.01655456988524735 and parameters: {'learning_rate': 0.00820751587697847, 'num_leaves': 12, 'subsample': 0.7877041158169154, 'colsample_bytree': 0.9455356853369701, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:48,888] Trial 16 finished with value: -0.05296596362332133 and parameters: {'learning_rate': 0.024586415200257457, 'num_leaves': 8, 'subsample': 0.6886823897456342, 'colsample_bytree': 0.6301417067410074, 'min_data_in_leaf': 5}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:49,300] Trial 17 finished with value: -0.026016830257893475 and parameters: {'learning_rate': 0.0022586710701374664, 'num_leaves': 12, 'subsample': 0.5916758737917746, 'colsample_bytree': 0.8495617534835714, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:49,592] Trial 18 finished with value: 0.036092867247939274 and parameters: {'learning_rate': 0.010672948665830897, 'num_leaves': 9, 'subsample': 0.9460948849774785, 'colsample_bytree': 0.7537626440202432, 'min_data_in_leaf': 20}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:49,984] Trial 19 finished with value: 0.022834874552749174 and parameters: {'learning_rate': 0.005247478301199273, 'num_leaves': 9, 'subsample': 0.9297094279625306, 'colsample_bytree': 0.7913454650401238, 'min_data_in_leaf': 20}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:50,360] Trial 20 finished with value: 0.026051960635363903 and parameters: {'learning_rate': 0.03299232910937659, 'num_leaves': 13, 'subsample': 0.9408394485243352, 'colsample_bytree': 0.7161980962704455, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:50,645] Trial 21 finished with value: 0.035462847893984 and parameters: {'learning_rate': 0.009195834586122683, 'num_leaves': 9, 'subsample': 0.8393209853007104, 'colsample_bytree': 0.6607186923302213, 'min_data_in_leaf': 20}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:50,950] Trial 22 finished with value: 0.03418798733256512 and parameters: {'learning_rate': 0.012651196758680702, 'num_leaves': 9, 'subsample': 0.8031836874518792, 'colsample_bytree': 0.6707910964218873, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:51,254] Trial 23 finished with value: 0.032765817564386325 and parameters: {'learning_rate': 0.008986050379087321, 'num_leaves': 8, 'subsample': 0.8354215184508369, 'colsample_bytree': 0.7466639287425022, 'min_data_in_leaf': 20}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:51,567] Trial 24 finished with value: -0.012025773041511955 and parameters: {'learning_rate': 0.002464521733425439, 'num_leaves': 10, 'subsample': 0.948302634956809, 'colsample_bytree': 0.7895737258111861, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:51,900] Trial 25 finished with value: 0.03549226696308749 and parameters: {'learning_rate': 0.00591935823793765, 'num_leaves': 11, 'subsample': 0.9053131587266288, 'colsample_bytree': 0.5588865393447895, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:52,217] Trial 26 finished with value: 0.04373631333405159 and parameters: {'learning_rate': 0.006398344232075887, 'num_leaves': 11, 'subsample': 0.9083089437562193, 'colsample_bytree': 0.5518648181965115, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:52,669] Trial 27 finished with value: 0.012444137442318204 and parameters: {'learning_rate': 0.02189074092567946, 'num_leaves': 16, 'subsample': 0.969753436002878, 'colsample_bytree': 0.9029677094867948, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:53,058] Trial 28 finished with value: 0.004884288963309613 and parameters: {'learning_rate': 0.0027630768260412672, 'num_leaves': 12, 'subsample': 0.9124002854072562, 'colsample_bytree': 0.856433886289063, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.0488057480996696.\n",
      "[I 2024-04-26 00:48:53,383] Trial 29 finished with value: 0.04655295781876227 and parameters: {'learning_rate': 0.005477276098923354, 'num_leaves': 11, 'subsample': 0.9554658270354852, 'colsample_bytree': 0.5413246894243753, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.0488057480996696.\n"
     ]
    }
   ],
   "source": [
    "# Train a LightGBM model with the new features\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(lambda trial: objective(trial, X_VIX_train, y_VIX_train), n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 2265, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 0.102259\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "RMSE: 0.08828676323276353\n",
      "R2 score: -0.40516678023698893\n"
     ]
    }
   ],
   "source": [
    "# Create a LightGBM model with the best parameters\n",
    "best_params = study.best_params\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "model.fit(X_VIX_train, y_VIX_train)\n",
    "\n",
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "y_pred = model.predict(X_VIX_test)\n",
    "mse = mean_squared_error(y_VIX_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_VIX_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FT5010AlgoTradingEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
