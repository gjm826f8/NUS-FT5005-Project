{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>^VIX^2</th>\n",
       "      <th>^SOX: Log_Returns</th>\n",
       "      <th>^VIX: Log_Returns</th>\n",
       "      <th>^VIX^2: Log_Returns</th>\n",
       "      <th>^SOX: Daily_RV</th>\n",
       "      <th>^SOX: Weekly_RV</th>\n",
       "      <th>^SOX: Daily_RV: Log_Returns</th>\n",
       "      <th>^SOX: Weekly_RV: Log_Returns</th>\n",
       "      <th>epsilon1</th>\n",
       "      <th>epsilon2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1370.685336</td>\n",
       "      <td>17.848712</td>\n",
       "      <td>368.417535</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.034397</td>\n",
       "      <td>-0.000643</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>972.265520</td>\n",
       "      <td>7.061094</td>\n",
       "      <td>414.852164</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>0.157364</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>3.169401</td>\n",
       "      <td>0.249976</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.223460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>351.450012</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>83.539606</td>\n",
       "      <td>-0.173119</td>\n",
       "      <td>-0.299831</td>\n",
       "      <td>-0.599662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>-15.944132</td>\n",
       "      <td>-1.344118</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>-1.151062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>616.957520</td>\n",
       "      <td>13.220000</td>\n",
       "      <td>174.768407</td>\n",
       "      <td>-0.008263</td>\n",
       "      <td>-0.044337</td>\n",
       "      <td>-0.088673</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>-1.783166</td>\n",
       "      <td>-0.091905</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>-0.099547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1084.644958</td>\n",
       "      <td>15.930000</td>\n",
       "      <td>253.764910</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>-0.023617</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-0.010562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1847.697540</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>428.490032</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.035816</td>\n",
       "      <td>0.071632</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.042794</td>\n",
       "      <td>1.822893</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.089466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4039.510010</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>6837.636504</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>0.768245</td>\n",
       "      <td>1.536490</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>0.271085</td>\n",
       "      <td>13.852759</td>\n",
       "      <td>1.793899</td>\n",
       "      <td>0.069019</td>\n",
       "      <td>1.679464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ^SOX         ^VIX       ^VIX^2  ^SOX: Log_Returns  \\\n",
       "count  2764.000000  2764.000000  2764.000000        2764.000000   \n",
       "mean   1370.685336    17.848712   368.417535           0.000691   \n",
       "std     972.265520     7.061094   414.852164           0.018128   \n",
       "min     351.450012     9.140000    83.539606          -0.173119   \n",
       "25%     616.957520    13.220000   174.768407          -0.008263   \n",
       "50%    1084.644958    15.930000   253.764910           0.001438   \n",
       "75%    1847.697540    20.700001   428.490032           0.010198   \n",
       "max    4039.510010    82.690002  6837.636504           0.105753   \n",
       "\n",
       "       ^VIX: Log_Returns  ^VIX^2: Log_Returns  ^SOX: Daily_RV  \\\n",
       "count        2764.000000          2764.000000     2764.000000   \n",
       "mean            0.000018             0.000036        0.000329   \n",
       "std             0.078682             0.157364        0.000950   \n",
       "min            -0.299831            -0.599662        0.000000   \n",
       "25%            -0.044337            -0.088673        0.000018   \n",
       "50%            -0.006419            -0.012839        0.000086   \n",
       "75%             0.035816             0.071632        0.000307   \n",
       "max             0.768245             1.536490        0.029970   \n",
       "\n",
       "       ^SOX: Weekly_RV  ^SOX: Daily_RV: Log_Returns  \\\n",
       "count      2764.000000                  2764.000000   \n",
       "mean          0.034397                    -0.000643   \n",
       "std           0.021463                     3.169401   \n",
       "min           0.003846                   -15.944132   \n",
       "25%           0.020776                    -1.783166   \n",
       "50%           0.029321                    -0.023617   \n",
       "75%           0.042794                     1.822893   \n",
       "max           0.271085                    13.852759   \n",
       "\n",
       "       ^SOX: Weekly_RV: Log_Returns     epsilon1     epsilon2  \n",
       "count                   2764.000000  2764.000000  2764.000000  \n",
       "mean                       0.000177     0.000510     0.001252  \n",
       "std                        0.249976     0.006797     0.223460  \n",
       "min                       -1.344118    -0.028591    -1.151062  \n",
       "25%                       -0.091905    -0.002782    -0.099547  \n",
       "50%                       -0.000573    -0.000760    -0.010562  \n",
       "75%                        0.085001     0.002514     0.089466  \n",
       "max                        1.793899     0.069019     1.679464  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data that was preprocessed in the EDA step\n",
    "data = pd.read_csv('input_data_2024-04-07.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SOX</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>^VIX^2</th>\n",
       "      <th>^SOX: Log_Returns</th>\n",
       "      <th>^VIX: Log_Returns</th>\n",
       "      <th>^VIX^2: Log_Returns</th>\n",
       "      <th>^SOX: Daily_RV</th>\n",
       "      <th>^SOX: Weekly_RV</th>\n",
       "      <th>^SOX: Daily_RV: Log_Returns</th>\n",
       "      <th>^SOX: Weekly_RV: Log_Returns</th>\n",
       "      <th>epsilon1</th>\n",
       "      <th>epsilon2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>382.589996</td>\n",
       "      <td>21.070000</td>\n",
       "      <td>443.944887</td>\n",
       "      <td>0.019451</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>3.783564e-04</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>3.874993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003712</td>\n",
       "      <td>-0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>386.279999</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>428.076122</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>-0.018200</td>\n",
       "      <td>-0.036399</td>\n",
       "      <td>9.213277e-05</td>\n",
       "      <td>0.026428</td>\n",
       "      <td>-1.412606</td>\n",
       "      <td>0.070729</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.070650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-11</th>\n",
       "      <td>387.890015</td>\n",
       "      <td>21.049999</td>\n",
       "      <td>443.102468</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.017250</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>1.730011e-05</td>\n",
       "      <td>0.026753</td>\n",
       "      <td>-1.672518</td>\n",
       "      <td>0.012215</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.013082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-12</th>\n",
       "      <td>391.750000</td>\n",
       "      <td>20.469999</td>\n",
       "      <td>419.020872</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>-0.027940</td>\n",
       "      <td>-0.055880</td>\n",
       "      <td>9.805058e-05</td>\n",
       "      <td>0.024366</td>\n",
       "      <td>1.734771</td>\n",
       "      <td>-0.093473</td>\n",
       "      <td>-0.002835</td>\n",
       "      <td>-0.092581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-13</th>\n",
       "      <td>383.470001</td>\n",
       "      <td>20.910000</td>\n",
       "      <td>437.228094</td>\n",
       "      <td>-0.021362</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>4.563559e-04</td>\n",
       "      <td>0.032283</td>\n",
       "      <td>1.537789</td>\n",
       "      <td>0.281362</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.280820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>2535.489990</td>\n",
       "      <td>20.870001</td>\n",
       "      <td>435.556935</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.051365</td>\n",
       "      <td>-0.102730</td>\n",
       "      <td>7.263040e-07</td>\n",
       "      <td>0.051167</td>\n",
       "      <td>-7.839736</td>\n",
       "      <td>-0.017006</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-0.031156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>2490.169922</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>468.722483</td>\n",
       "      <td>-0.018036</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>0.073385</td>\n",
       "      <td>3.252958e-04</td>\n",
       "      <td>0.052457</td>\n",
       "      <td>6.104522</td>\n",
       "      <td>0.024898</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.011801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>2453.489990</td>\n",
       "      <td>22.139999</td>\n",
       "      <td>490.179573</td>\n",
       "      <td>-0.014839</td>\n",
       "      <td>0.022380</td>\n",
       "      <td>0.044761</td>\n",
       "      <td>2.202094e-04</td>\n",
       "      <td>0.054155</td>\n",
       "      <td>-0.390156</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>-0.006444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>2534.949951</td>\n",
       "      <td>21.440001</td>\n",
       "      <td>459.673623</td>\n",
       "      <td>0.032662</td>\n",
       "      <td>-0.032128</td>\n",
       "      <td>-0.064255</td>\n",
       "      <td>1.066832e-03</td>\n",
       "      <td>0.058801</td>\n",
       "      <td>1.577870</td>\n",
       "      <td>0.082301</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>2532.110107</td>\n",
       "      <td>21.670000</td>\n",
       "      <td>469.588903</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>1.256426e-06</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>-6.744178</td>\n",
       "      <td>-0.380821</td>\n",
       "      <td>-0.011787</td>\n",
       "      <td>-0.318251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2764 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ^SOX       ^VIX      ^VIX^2  ^SOX: Log_Returns  \\\n",
       "Date                                                                \n",
       "2012-01-09   382.589996  21.070000  443.944887           0.019451   \n",
       "2012-01-10   386.279999  20.690001  428.076122           0.009599   \n",
       "2012-01-11   387.890015  21.049999  443.102468           0.004159   \n",
       "2012-01-12   391.750000  20.469999  419.020872           0.009902   \n",
       "2012-01-13   383.470001  20.910000  437.228094          -0.021362   \n",
       "...                 ...        ...         ...                ...   \n",
       "2022-12-23  2535.489990  20.870001  435.556935           0.000852   \n",
       "2022-12-27  2490.169922  21.650000  468.722483          -0.018036   \n",
       "2022-12-28  2453.489990  22.139999  490.179573          -0.014839   \n",
       "2022-12-29  2534.949951  21.440001  459.673623           0.032662   \n",
       "2022-12-30  2532.110107  21.670000  469.588903          -0.001121   \n",
       "\n",
       "            ^VIX: Log_Returns  ^VIX^2: Log_Returns  ^SOX: Daily_RV  \\\n",
       "Date                                                                 \n",
       "2012-01-09           0.021104             0.042208    3.783564e-04   \n",
       "2012-01-10          -0.018200            -0.036399    9.213277e-05   \n",
       "2012-01-11           0.017250             0.034500    1.730011e-05   \n",
       "2012-01-12          -0.027940            -0.055880    9.805058e-05   \n",
       "2012-01-13           0.021267             0.042534    4.563559e-04   \n",
       "...                       ...                  ...             ...   \n",
       "2022-12-23          -0.051365            -0.102730    7.263040e-07   \n",
       "2022-12-27           0.036693             0.073385    3.252958e-04   \n",
       "2022-12-28           0.022380             0.044761    2.202094e-04   \n",
       "2022-12-29          -0.032128            -0.064255    1.066832e-03   \n",
       "2022-12-30           0.010670             0.021341    1.256426e-06   \n",
       "\n",
       "            ^SOX: Weekly_RV  ^SOX: Daily_RV: Log_Returns  \\\n",
       "Date                                                       \n",
       "2012-01-09         0.024624                     3.874993   \n",
       "2012-01-10         0.026428                    -1.412606   \n",
       "2012-01-11         0.026753                    -1.672518   \n",
       "2012-01-12         0.024366                     1.734771   \n",
       "2012-01-13         0.032283                     1.537789   \n",
       "...                     ...                          ...   \n",
       "2022-12-23         0.051167                    -7.839736   \n",
       "2022-12-27         0.052457                     6.104522   \n",
       "2022-12-28         0.054155                    -0.390156   \n",
       "2022-12-29         0.058801                     1.577870   \n",
       "2022-12-30         0.040179                    -6.744178   \n",
       "\n",
       "            ^SOX: Weekly_RV: Log_Returns  epsilon1  epsilon2  \n",
       "Date                                                          \n",
       "2012-01-09                      0.000000 -0.003712 -0.000078  \n",
       "2012-01-10                      0.070729  0.001456  0.070650  \n",
       "2012-01-11                      0.012215 -0.000044  0.013082  \n",
       "2012-01-12                     -0.093473 -0.002835 -0.092581  \n",
       "2012-01-13                      0.281362  0.007507  0.280820  \n",
       "...                                  ...       ...       ...  \n",
       "2022-12-23                     -0.017006 -0.000399 -0.031156  \n",
       "2022-12-27                      0.024898  0.002141  0.011801  \n",
       "2022-12-28                      0.031859  0.002614 -0.006444  \n",
       "2022-12-29                      0.082301  0.005857  0.066700  \n",
       "2022-12-30                     -0.380821 -0.011787 -0.318251  \n",
       "\n",
       "[2764 rows x 12 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SOX', 'VIX', 'VIX2', 'SOX Log_Returns', 'VIX Log_Returns',\n",
       "       'VIX2 Log_Returns', 'SOX Daily_RV', 'SOX Weekly_RV',\n",
       "       'SOX Daily_RV Log_Returns', 'SOX Weekly_RV Log_Returns', 'epsilon1',\n",
       "       'epsilon2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename the columns (delete special characters)\n",
    "data = data.rename(columns=lambda x: x.replace('^', '').replace(':', ''))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "1. Withormalization\n",
    "2. Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOX</th>\n",
       "      <th>VIX</th>\n",
       "      <th>VIX2</th>\n",
       "      <th>SOX Log_Returns</th>\n",
       "      <th>VIX Log_Returns</th>\n",
       "      <th>VIX2 Log_Returns</th>\n",
       "      <th>SOX Daily_RV</th>\n",
       "      <th>SOX Weekly_RV</th>\n",
       "      <th>SOX Daily_RV Log_Returns</th>\n",
       "      <th>SOX Weekly_RV Log_Returns</th>\n",
       "      <th>epsilon1</th>\n",
       "      <th>epsilon2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>756.402765</td>\n",
       "      <td>17.848712</td>\n",
       "      <td>334.242329</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.034397</td>\n",
       "      <td>1.027578</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.010301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>189.746632</td>\n",
       "      <td>7.061094</td>\n",
       "      <td>219.896506</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>0.154199</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>1.998203</td>\n",
       "      <td>0.215591</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.202905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>351.450012</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>83.539606</td>\n",
       "      <td>-0.173119</td>\n",
       "      <td>-0.299831</td>\n",
       "      <td>-0.318273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>-0.318273</td>\n",
       "      <td>-0.318273</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>-0.318273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>616.957520</td>\n",
       "      <td>13.220000</td>\n",
       "      <td>174.768407</td>\n",
       "      <td>-0.008263</td>\n",
       "      <td>-0.044337</td>\n",
       "      <td>-0.088673</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.020776</td>\n",
       "      <td>-0.318273</td>\n",
       "      <td>-0.091905</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>-0.099547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>907.340027</td>\n",
       "      <td>15.930000</td>\n",
       "      <td>253.764910</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>-0.006419</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>-0.023617</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>-0.000760</td>\n",
       "      <td>-0.010562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>907.340027</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>428.490032</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>0.035816</td>\n",
       "      <td>0.071632</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.042794</td>\n",
       "      <td>1.822893</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.089466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>907.340027</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>907.340027</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>0.768245</td>\n",
       "      <td>1.536490</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>0.271085</td>\n",
       "      <td>13.852759</td>\n",
       "      <td>1.793899</td>\n",
       "      <td>0.069019</td>\n",
       "      <td>1.679464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SOX          VIX         VIX2  SOX Log_Returns  \\\n",
       "count  2764.000000  2764.000000  2764.000000      2764.000000   \n",
       "mean    756.402765    17.848712   334.242329         0.000691   \n",
       "std     189.746632     7.061094   219.896506         0.018128   \n",
       "min     351.450012     9.140000    83.539606        -0.173119   \n",
       "25%     616.957520    13.220000   174.768407        -0.008263   \n",
       "50%     907.340027    15.930000   253.764910         0.001438   \n",
       "75%     907.340027    20.700001   428.490032         0.010198   \n",
       "max     907.340027    82.690002   907.340027         0.105753   \n",
       "\n",
       "       VIX Log_Returns  VIX2 Log_Returns  SOX Daily_RV  SOX Weekly_RV  \\\n",
       "count      2764.000000       2764.000000   2764.000000    2764.000000   \n",
       "mean          0.000018          0.001322      0.000329       0.034397   \n",
       "std           0.078682          0.154199      0.000950       0.021463   \n",
       "min          -0.299831         -0.318273      0.000000       0.003846   \n",
       "25%          -0.044337         -0.088673      0.000018       0.020776   \n",
       "50%          -0.006419         -0.012839      0.000086       0.029321   \n",
       "75%           0.035816          0.071632      0.000307       0.042794   \n",
       "max           0.768245          1.536490      0.029970       0.271085   \n",
       "\n",
       "       SOX Daily_RV Log_Returns  SOX Weekly_RV Log_Returns     epsilon1  \\\n",
       "count               2764.000000                2764.000000  2764.000000   \n",
       "mean                   1.027578                   0.015640     0.000510   \n",
       "std                    1.998203                   0.215591     0.006797   \n",
       "min                   -0.318273                  -0.318273    -0.028591   \n",
       "25%                   -0.318273                  -0.091905    -0.002782   \n",
       "50%                   -0.023617                  -0.000573    -0.000760   \n",
       "75%                    1.822893                   0.085001     0.002514   \n",
       "max                   13.852759                   1.793899     0.069019   \n",
       "\n",
       "          epsilon2  \n",
       "count  2764.000000  \n",
       "mean      0.010301  \n",
       "std       0.202905  \n",
       "min      -0.318273  \n",
       "25%      -0.099547  \n",
       "50%      -0.010562  \n",
       "75%       0.089466  \n",
       "max       1.679464  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform numerical data with withormalization\n",
    "from scipy.stats.mstats import winsorize\n",
    "data = pd.DataFrame(winsorize(np.array(data), limits=[0.05, 0.05]), columns=data.columns, index=data.index)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOX</th>\n",
       "      <th>VIX</th>\n",
       "      <th>VIX2</th>\n",
       "      <th>SOX Log_Returns</th>\n",
       "      <th>VIX Log_Returns</th>\n",
       "      <th>VIX2 Log_Returns</th>\n",
       "      <th>SOX Daily_RV</th>\n",
       "      <th>SOX Weekly_RV</th>\n",
       "      <th>SOX Daily_RV Log_Returns</th>\n",
       "      <th>SOX Weekly_RV Log_Returns</th>\n",
       "      <th>epsilon1</th>\n",
       "      <th>epsilon2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "      <td>2764.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.728476</td>\n",
       "      <td>0.118405</td>\n",
       "      <td>0.304325</td>\n",
       "      <td>0.623260</td>\n",
       "      <td>0.280737</td>\n",
       "      <td>0.172310</td>\n",
       "      <td>0.010976</td>\n",
       "      <td>0.114322</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>0.158090</td>\n",
       "      <td>0.298137</td>\n",
       "      <td>0.164473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.341338</td>\n",
       "      <td>0.096004</td>\n",
       "      <td>0.266929</td>\n",
       "      <td>0.065003</td>\n",
       "      <td>0.073667</td>\n",
       "      <td>0.083137</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.080313</td>\n",
       "      <td>0.141006</td>\n",
       "      <td>0.102071</td>\n",
       "      <td>0.069637</td>\n",
       "      <td>0.101567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.477626</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>0.110741</td>\n",
       "      <td>0.591154</td>\n",
       "      <td>0.239210</td>\n",
       "      <td>0.123789</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107173</td>\n",
       "      <td>0.264416</td>\n",
       "      <td>0.109487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>0.206634</td>\n",
       "      <td>0.625939</td>\n",
       "      <td>0.274711</td>\n",
       "      <td>0.164675</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.095328</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.150414</td>\n",
       "      <td>0.285131</td>\n",
       "      <td>0.154030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157172</td>\n",
       "      <td>0.418731</td>\n",
       "      <td>0.657351</td>\n",
       "      <td>0.314254</td>\n",
       "      <td>0.210218</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.145744</td>\n",
       "      <td>0.151095</td>\n",
       "      <td>0.190929</td>\n",
       "      <td>0.318665</td>\n",
       "      <td>0.204101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SOX          VIX         VIX2  SOX Log_Returns  \\\n",
       "count  2764.000000  2764.000000  2764.000000      2764.000000   \n",
       "mean      0.728476     0.118405     0.304325         0.623260   \n",
       "std       0.341338     0.096004     0.266929         0.065003   \n",
       "min       0.000000     0.000000     0.000000         0.000000   \n",
       "25%       0.477626     0.055472     0.110741         0.591154   \n",
       "50%       1.000000     0.092318     0.206634         0.625939   \n",
       "75%       1.000000     0.157172     0.418731         0.657351   \n",
       "max       1.000000     1.000000     1.000000         1.000000   \n",
       "\n",
       "       VIX Log_Returns  VIX2 Log_Returns  SOX Daily_RV  SOX Weekly_RV  \\\n",
       "count      2764.000000       2764.000000   2764.000000    2764.000000   \n",
       "mean          0.280737          0.172310      0.010976       0.114322   \n",
       "std           0.073667          0.083137      0.031686       0.080313   \n",
       "min           0.000000          0.000000      0.000000       0.000000   \n",
       "25%           0.239210          0.123789      0.000606       0.063354   \n",
       "50%           0.274711          0.164675      0.002854       0.095328   \n",
       "75%           0.314254          0.210218      0.010252       0.145744   \n",
       "max           1.000000          1.000000      1.000000       1.000000   \n",
       "\n",
       "       SOX Daily_RV Log_Returns  SOX Weekly_RV Log_Returns     epsilon1  \\\n",
       "count               2764.000000                2764.000000  2764.000000   \n",
       "mean                   0.094972                   0.158090     0.298137   \n",
       "std                    0.141006                   0.102071     0.069637   \n",
       "min                    0.000000                   0.000000     0.000000   \n",
       "25%                    0.000000                   0.107173     0.264416   \n",
       "50%                    0.020793                   0.150414     0.285131   \n",
       "75%                    0.151095                   0.190929     0.318665   \n",
       "max                    1.000000                   1.000000     1.000000   \n",
       "\n",
       "          epsilon2  \n",
       "count  2764.000000  \n",
       "mean      0.164473  \n",
       "std       0.101567  \n",
       "min       0.000000  \n",
       "25%       0.109487  \n",
       "50%       0.154030  \n",
       "75%       0.204101  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform numerical data with min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Dataset Preparation\n",
    "1. Training Data : 2012-2020\n",
    "2. Testing Data: 2021-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (training data from 2012 to 2020, test data from 2021 to 2022)\n",
    "data_train = data.loc['2012-01-01':'2020-12-31']\n",
    "data_test = data.loc['2021-01-01':'2022-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Attributes(X) and Target(Y)\n",
    "1. X \\\n",
    "    1.1 Index Value: ^SOX, ^VIX \\\n",
    "    1.2 Square Value: ^VIX^2 \\\n",
    "    1.3 Log Return: ^SOX, ^VIX, ^VIX^2\n",
    "    \n",
    "2. y: Weekly Relative Volatility of ^SOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X_base_train = data_train[['SOX', 'VIX', 'VIX2', 'SOX Log_Returns', 'VIX Log_Returns', 'VIX2 Log_Returns']]\n",
    "y_train = data_train[['SOX Weekly_RV']]\n",
    "X_base_test = data_test[['SOX', 'VIX', 'VIX2', 'SOX Log_Returns', 'VIX Log_Returns', 'VIX2 Log_Returns']]\n",
    "y_test = data_test[['SOX Weekly_RV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model Training and Performance\n",
    "1. Decesion Tree Regressor\n",
    "2. Linear Regression\n",
    "\n",
    "performance matrix\n",
    "1. Root Mean Square Error\n",
    "2. R-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Best score: 0.1985151583694864\n"
     ]
    }
   ],
   "source": [
    "# Create a decision tree regressor model and use parameters from the grid search\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_base_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 5),\n",
    "    'min_samples_split': range(2, 5),\n",
    "    'min_samples_leaf': range(3, 8),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, n_jobs=-1, verbose=-1)\n",
    "grid_search.fit(X_base_train, y_train)\n",
    "\n",
    "# Report the best model parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.06862696849647454\n",
      "R2 score: 0.15808918073311362\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = grid_search.best_estimator_\n",
    "y_pred = model.predict(X_base_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_base_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.06921342508611589\n",
      "R2 score: 0.14363848237365262\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "y_pred = model.predict(X_base_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Model Training and Performance\n",
    "Hyperparamter tuning: Optuna\n",
    "\n",
    "Time series split = 5\n",
    "\n",
    "Objective function: Mean(Root Mean Square Error)\n",
    "\n",
    "Performance matrix:\n",
    "1. Root Mean Square Error\n",
    "2. R-square\n",
    "\n",
    "Reference:\\\n",
    "https://forecastegy.com/posts/how-to-use-optuna-to-tune-lightgbm-hyperparameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # further split the data into training and validation sets\n",
    "# data_train = data.loc['2012-01-01':'2019-12-31']\n",
    "# data_val = data.loc['2020-01-01':'2020-12-31']\n",
    "\n",
    "# # Split the data into features and target\n",
    "# X_base_train = data_train[['SOX', 'VIX', 'VIX2', 'SOX Log_Returns', 'VIX Log_Returns', 'VIX2 Log_Returns']]\n",
    "# y_train = data_train[['SOX Weekly_RV']]\n",
    "# X_base_val = data_val[['SOX', 'VIX', 'VIX2', 'SOX Log_Returns', 'VIX Log_Returns', 'VIX2 Log_Returns']]\n",
    "# y_val = data_val[['SOX Weekly_RV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"n_estimators\": 300,\n",
    "        \"verbosity\": -1,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**4),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 20),\n",
    "    }\n",
    "\n",
    "    rmse_scores = np.array([])\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "    for train_index, val_index in tscv.split(X_base_train):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "        X_t, X_val = X_base_train.iloc[train_index], X_base_train.iloc[val_index]\n",
    "        y_t, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        model.fit(X_t, y_t)\n",
    "        predictions = model.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, predictions, squared=False)\n",
    "        rmse_scores = np.append(rmse_scores, rmse)\n",
    "    return rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:30:45,135] A new study created in memory with name: no-name-52bb7e73-9419-432f-b6ad-4e1d6cffe385\n",
      "[I 2024-04-25 01:30:45,518] Trial 0 finished with value: 0.05951631504644224 and parameters: {'learning_rate': 0.03418273435208915, 'num_leaves': 14, 'subsample': 0.7408923018384463, 'colsample_bytree': 0.8775000733250338, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.05951631504644224.\n",
      "[I 2024-04-25 01:30:45,766] Trial 1 finished with value: 0.05700941443864247 and parameters: {'learning_rate': 0.030980360854011683, 'num_leaves': 8, 'subsample': 0.5577591170108473, 'colsample_bytree': 0.7402132309662695, 'min_data_in_leaf': 9}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:46,142] Trial 2 finished with value: 0.05787460225063964 and parameters: {'learning_rate': 0.023998305299243163, 'num_leaves': 15, 'subsample': 0.8196687473981048, 'colsample_bytree': 0.6648544021837625, 'min_data_in_leaf': 16}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:46,467] Trial 3 finished with value: 0.059407715264217065 and parameters: {'learning_rate': 0.004835474998265996, 'num_leaves': 11, 'subsample': 0.9889921414032337, 'colsample_bytree': 0.7990032820884427, 'min_data_in_leaf': 10}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:46,867] Trial 4 finished with value: 0.05895705852582853 and parameters: {'learning_rate': 0.004536667293089595, 'num_leaves': 15, 'subsample': 0.8119198738726521, 'colsample_bytree': 0.7795897379085519, 'min_data_in_leaf': 8}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:47,183] Trial 5 finished with value: 0.05756539723551468 and parameters: {'learning_rate': 0.03827108833917013, 'num_leaves': 13, 'subsample': 0.527341974363793, 'colsample_bytree': 0.7206007680264954, 'min_data_in_leaf': 20}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:47,507] Trial 6 finished with value: 0.062030798299477954 and parameters: {'learning_rate': 0.0028802723474665106, 'num_leaves': 11, 'subsample': 0.5063543179321193, 'colsample_bytree': 0.7371614050969277, 'min_data_in_leaf': 15}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:47,696] Trial 7 finished with value: 0.06651176778551443 and parameters: {'learning_rate': 0.0016734216282715925, 'num_leaves': 4, 'subsample': 0.6538363313765941, 'colsample_bytree': 0.7475025070476955, 'min_data_in_leaf': 9}. Best is trial 1 with value: 0.05700941443864247.\n",
      "[I 2024-04-25 01:30:47,984] Trial 8 finished with value: 0.05680797513274831 and parameters: {'learning_rate': 0.010274798419884164, 'num_leaves': 8, 'subsample': 0.6449760895852821, 'colsample_bytree': 0.6776728937421428, 'min_data_in_leaf': 5}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:48,334] Trial 9 finished with value: 0.06143147797273124 and parameters: {'learning_rate': 0.002822317495393827, 'num_leaves': 10, 'subsample': 0.5002954525038914, 'colsample_bytree': 0.9516480687225739, 'min_data_in_leaf': 8}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:48,600] Trial 10 finished with value: 0.05689761173430367 and parameters: {'learning_rate': 0.011828879968447559, 'num_leaves': 6, 'subsample': 0.6492759933583597, 'colsample_bytree': 0.5026904316773579, 'min_data_in_leaf': 1}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:48,853] Trial 11 finished with value: 0.05696110979029799 and parameters: {'learning_rate': 0.011355484809249469, 'num_leaves': 6, 'subsample': 0.6508282683790279, 'colsample_bytree': 0.5033612038222778, 'min_data_in_leaf': 1}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:49,037] Trial 12 finished with value: 0.05918973089625309 and parameters: {'learning_rate': 0.01179977064064318, 'num_leaves': 2, 'subsample': 0.6491193156563277, 'colsample_bytree': 0.5015903498154184, 'min_data_in_leaf': 1}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:49,283] Trial 13 finished with value: 0.05734950955289904 and parameters: {'learning_rate': 0.016064441407334193, 'num_leaves': 7, 'subsample': 0.7196657711924647, 'colsample_bytree': 0.6040319459510766, 'min_data_in_leaf': 5}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:49,483] Trial 14 finished with value: 0.05948808342754732 and parameters: {'learning_rate': 0.08505847989034396, 'num_leaves': 5, 'subsample': 0.6056637649742278, 'colsample_bytree': 0.5951687713107304, 'min_data_in_leaf': 4}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:49,763] Trial 15 finished with value: 0.05786269694944366 and parameters: {'learning_rate': 0.006632695549723305, 'num_leaves': 9, 'subsample': 0.8122199957713124, 'colsample_bytree': 0.5913008724730769, 'min_data_in_leaf': 5}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:49,927] Trial 16 finished with value: 0.06926873135630134 and parameters: {'learning_rate': 0.0010093900660745063, 'num_leaves': 3, 'subsample': 0.5907650813487668, 'colsample_bytree': 0.65798092303857, 'min_data_in_leaf': 2}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:50,165] Trial 17 finished with value: 0.05807256616090376 and parameters: {'learning_rate': 0.007731232367858216, 'num_leaves': 7, 'subsample': 0.9544635340716441, 'colsample_bytree': 0.5632330493766252, 'min_data_in_leaf': 14}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:50,369] Trial 18 finished with value: 0.05779401019599956 and parameters: {'learning_rate': 0.07171756370186518, 'num_leaves': 5, 'subsample': 0.7091406129171818, 'colsample_bytree': 0.8420135419875674, 'min_data_in_leaf': 6}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:50,636] Trial 19 finished with value: 0.05692691037847346 and parameters: {'learning_rate': 0.017359831956685532, 'num_leaves': 9, 'subsample': 0.6870483703155466, 'colsample_bytree': 0.6721346766214881, 'min_data_in_leaf': 12}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:50,969] Trial 20 finished with value: 0.060005046276789396 and parameters: {'learning_rate': 0.05723126105480419, 'num_leaves': 12, 'subsample': 0.8739891308215244, 'colsample_bytree': 0.9875045982945494, 'min_data_in_leaf': 3}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:51,254] Trial 21 finished with value: 0.056979137786820414 and parameters: {'learning_rate': 0.017441428346639257, 'num_leaves': 9, 'subsample': 0.6740216773233523, 'colsample_bytree': 0.6777595875492906, 'min_data_in_leaf': 12}. Best is trial 8 with value: 0.05680797513274831.\n",
      "[I 2024-04-25 01:30:51,534] Trial 22 finished with value: 0.05630034948963518 and parameters: {'learning_rate': 0.0160924961957909, 'num_leaves': 7, 'subsample': 0.6075196426395089, 'colsample_bytree': 0.5469821813301865, 'min_data_in_leaf': 6}. Best is trial 22 with value: 0.05630034948963518.\n",
      "[I 2024-04-25 01:30:51,785] Trial 23 finished with value: 0.056787778493232875 and parameters: {'learning_rate': 0.009726353070799628, 'num_leaves': 7, 'subsample': 0.5867113280822811, 'colsample_bytree': 0.5426936992929915, 'min_data_in_leaf': 7}. Best is trial 22 with value: 0.05630034948963518.\n",
      "[I 2024-04-25 01:30:52,050] Trial 24 finished with value: 0.058018847367051485 and parameters: {'learning_rate': 0.006641808125016911, 'num_leaves': 6, 'subsample': 0.5954722616334029, 'colsample_bytree': 0.5652030992254221, 'min_data_in_leaf': 7}. Best is trial 22 with value: 0.05630034948963518.\n",
      "[I 2024-04-25 01:30:52,315] Trial 25 finished with value: 0.05595076292718815 and parameters: {'learning_rate': 0.02127579022471743, 'num_leaves': 8, 'subsample': 0.5650014023623267, 'colsample_bytree': 0.5479255770133339, 'min_data_in_leaf': 6}. Best is trial 25 with value: 0.05595076292718815.\n",
      "[I 2024-04-25 01:30:52,561] Trial 26 finished with value: 0.05721890727354266 and parameters: {'learning_rate': 0.05029080772012434, 'num_leaves': 8, 'subsample': 0.557539192969158, 'colsample_bytree': 0.5535882757632105, 'min_data_in_leaf': 11}. Best is trial 25 with value: 0.05595076292718815.\n",
      "[I 2024-04-25 01:30:52,751] Trial 27 finished with value: 0.05551816318497569 and parameters: {'learning_rate': 0.025333670252240936, 'num_leaves': 4, 'subsample': 0.5515428530066189, 'colsample_bytree': 0.6268705123070436, 'min_data_in_leaf': 6}. Best is trial 27 with value: 0.05551816318497569.\n",
      "[I 2024-04-25 01:30:52,896] Trial 28 finished with value: 0.055870149400549594 and parameters: {'learning_rate': 0.023199078336336554, 'num_leaves': 2, 'subsample': 0.5488457883525586, 'colsample_bytree': 0.6271008006108548, 'min_data_in_leaf': 3}. Best is trial 27 with value: 0.05551816318497569.\n",
      "[I 2024-04-25 01:30:53,044] Trial 29 finished with value: 0.05534440442178581 and parameters: {'learning_rate': 0.028794398546408004, 'num_leaves': 2, 'subsample': 0.531292748331675, 'colsample_bytree': 0.6387891235129918, 'min_data_in_leaf': 3}. Best is trial 29 with value: 0.05534440442178581.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 2261, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 0.102218\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.6387891235129918,\n",
       "              learning_rate=0.028794398546408004, min_data_in_leaf=3,\n",
       "              num_leaves=2, subsample=0.531292748331675)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.6387891235129918,\n",
       "              learning_rate=0.028794398546408004, min_data_in_leaf=3,\n",
       "              num_leaves=2, subsample=0.531292748331675)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.6387891235129918,\n",
       "              learning_rate=0.028794398546408004, min_data_in_leaf=3,\n",
       "              num_leaves=2, subsample=0.531292748331675)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the R2 score for the best model\n",
    "best_params = study.best_params\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "model.fit(X_base_train, y_train)\n",
    "# y_pred = model.predict(X_base_val)\n",
    "# r2 = r2_score(y_val, y_pred)\n",
    "# print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "RMSE: 0.07740778285866126\n",
      "R2 score: -0.0711387172643203\n"
     ]
    }
   ],
   "source": [
    "# Predict the target variable for the test set and calculate the RMSE and R2 score\n",
    "y_pred = model.predict(X_base_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "log of yesterday volatility, square of yesterday volatility, log of VIX, log of past 5 days VIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FT5010AlgoTradingEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
